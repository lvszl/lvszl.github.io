---

---

![](https://raw.githubusercontent.com/lvszl/figure/master/20231031105532.png)

发布于2022 CVPR

被Show Me The Best Outfit for A Certain Scene: A Scene-aware Fashion Recommender System（WWW2023）作为baseline

# 主旨

提出了Outfit Transformer框架，来学习时尚推荐中有效的服装级表示。

主要使用了自注意力机制，基于Transformer。

如何解决兼容性预测和互补物品的检索任务：利用Transformer和自注意力机制来编码服装中物品之间的兼容关系：

1. 对于兼容性越策：使用一个服装令牌来捕获全局的服装表示，并使用分类损失进行训练
2. 对于互补物品检索，设计了一个目标物品令牌，编码了部分服装的兼容性和目标物品的描述。

具体流程如下图：

![](https://raw.githubusercontent.com/lvszl/figure/master/20231031110020.png)

对于CIR（兼容性物品搜索）：该框架学习了一个嵌入表示，用于编码部分装备的整体兼容性，以及一个目标物品描述，该描述用于通过KNN（K-最近邻）搜索来检索与整套装备相匹配的兼容物品。

对于CP（兼容性预测）：该框架学习了一个表示整体装备兼容性的装备级别表示，以预测装备的兼容性分数。



# 详细结构

![](https://raw.githubusercontent.com/lvszl/figure/master/20231031110840.png)

这个框架中，图a是兼容性预测，将图片信息和文聘信息一起输入，然后聚合成一个向量，通过Transformer变换后，再通过名为Focal loss的损失函数来进行训练。具体应该是训练这个outfit token，作者用这个东西来表征一个套装。

图b是补充物品检索，通过输入一个表示目标物品的token，和套装物品的集合，来学习一个目标物品的嵌入向量，这个嵌入向量可以来表示检索兼容的物品来获得一个完整的套装。



## 损失函数

![](https://raw.githubusercontent.com/lvszl/figure/master/20231031113043.png)

（a）是已有的训练方法，它是一种在训练时比较每个服装搭配中的每一对物品，以确定它们之间的兼容性并对它们进行排名的方法。这意味着需要进行大量的成对计算，以评估每对物品的兼容性。

（b）是本文提出的方法，他们的框架生成一个单一的目标物品嵌入（embedding），用于捕获整套搭配的兼容性，而不需要对搭配中的每个物品进行成对计算。这意味着他们的方法更高效，因为它不需要在每个物品对之间执行兼容性计算。

Set-wise Outfit Ranking Loss的过程如下：

1. 首先，该方法使用深度学习模型提取出每个物品的特征向量。
2. 然后，从数据集中随机选择一个物品作为正样本，并从剩余的物品中选择其余物品作为部分outfit。
3. 在训练过程中，采用了逐步增加负样本难度的课程学习策略。首先，从与正样本同一高级类别的物品中采样负样本，然后逐渐采样更难的细粒度类别中的负样本。这样做的目的是让模型逐渐学习到更具区分性的特征，以区分那些之间差异非常微小的物品。
4. 接下来，根据正样本和负样本计算出一个set-wise outfit ranking loss。该损失函数的目标是优化正样本和负样本之间的相对距离，使得目标物品的嵌入向量接近正样本的嵌入向量，远离负样本的嵌入向量。
5. set-wise outfit ranking loss由两个组成部分组成：$L(t, p, N)_{All}$ 和 $L(t, p, N)_{Hard}$。其中，$L(t, p, N)_{All} $考虑了所有采样的负样本，而$ L(t, p, N)_{Hard} $仅考虑了较难的负样本。这样设计的目的是使模型能够更好地学习到不同类别下物品之间的区别。
6. 最后，根据生成的目标物品嵌入向量，从数据库中检索与部分outfit兼容且匹配目标物品描述的物品。


![](https://raw.githubusercontent.com/lvszl/figure/master/20231031115113.png)

